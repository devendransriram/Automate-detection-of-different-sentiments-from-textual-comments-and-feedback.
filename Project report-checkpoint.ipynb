{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Of The Student:   Sriram Devendran\n",
    "## Project Topic: Automate detection of different sentiments from textual comments and feedback.\n",
    "## Name of the Organization:   TCS iON\n",
    "## Name of the Industry Mentor:    Soumyadip mal\n",
    "## Name of the Institute:   Vels Institute Of Science Technology and Advance Studies\n",
    "## I have taken a problem statements and I have performed the neccessary text mining for automatic detection of different sentimental comments whether its positive or negative textual comments and feedback!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be trying to understand sentiment of tweets about the company Apple, By using the twitter for better understand public perception, Apple wants to monitor how people feel over time and how people receive new announcements.\n",
    "\n",
    "Our challenge is to see if we can correctly classify tweets as being negative, positive, or neither about Apple.\n",
    "\n",
    "Sentiment Mining - Apple\n",
    "•\tApple is a computer company known for its laptops, phones, tablets, and personal media players\n",
    "•\tLarge numbers of fans, large number of “haters”\n",
    "•\tApple wants to monitor how people feel about them over time, and how people receive new announcements.\n",
    "\n",
    "Problem Statement:\n",
    "•\tCan we correctly classify tweets as being negative, positive, or neither about Apple?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:33.527545Z",
     "start_time": "2020-04-16T13:31:32.032505Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import nltk \n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install wordcloud , to install wordcloud\n",
    "from wordcloud import WordCloud, STOPWORDS #calling WordCloud and Stopwords\n",
    "from nltk.corpus import stopwords  #stopwords\n",
    "from nltk.tokenize import word_tokenize #word tokenizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the csv file available in the working or specified directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:33.537515Z",
     "start_time": "2020-04-16T13:31:33.528504Z"
    }
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.chdir('C:\\\\GL Class\\DSBA - Python\\Machine Learning\\Week 3')\n",
    "Apple_tweets = pd.read_csv(\"Apple_tweets .csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:33.756926Z",
     "start_time": "2020-04-16T13:31:33.539487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I have to say, Apple has by far the best custo...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>iOS 7 is so fricking smooth &amp; beautiful!! #Tha...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LOVE U @APPLE</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Thank you @apple, loving my new iPhone 5S!!!!!...</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>.@apple has the best customer service. In and ...</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Avg\n",
       "0  I have to say, Apple has by far the best custo...  2.0\n",
       "1  iOS 7 is so fricking smooth & beautiful!! #Tha...  2.0\n",
       "2                                      LOVE U @APPLE  1.8\n",
       "3  Thank you @apple, loving my new iPhone 5S!!!!!...  1.8\n",
       "4  .@apple has the best customer service. In and ...  1.8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apple_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Exploration in Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To create a temporary function lambda can be used. These functions do not require a name like a def function, however the output is same as defining a permanent function**\n",
    "**As these function are temporary, memory comsumption is less in comparison to permanent function. Also there are multiple ways to get a similar output**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:33.874611Z",
     "start_time": "2020-04-16T13:31:33.758921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>totalwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I have to say, Apple has by far the best custo...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>iOS 7 is so fricking smooth &amp; beautiful!! #Tha...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LOVE U @APPLE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Thank you @apple, loving my new iPhone 5S!!!!!...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>.@apple has the best customer service. In and ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  totalwords\n",
       "0  I have to say, Apple has by far the best custo...          19\n",
       "1  iOS 7 is so fricking smooth & beautiful!! #Tha...          10\n",
       "2                                      LOVE U @APPLE           3\n",
       "3  Thank you @apple, loving my new iPhone 5S!!!!!...          11\n",
       "4  .@apple has the best customer service. In and ...          16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's get a word count without writing a lambda function\n",
    "\n",
    "Apple_tweets['totalwords'] = [len(x.split()) for x in Apple_tweets['Tweet'].tolist()]\n",
    "Apple_tweets[['Tweet','totalwords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:34.038179Z",
     "start_time": "2020-04-16T13:31:33.876573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I have to say, Apple has by far the best custo...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>iOS 7 is so fricking smooth &amp; beautiful!! #Tha...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LOVE U @APPLE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Thank you @apple, loving my new iPhone 5S!!!!!...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>.@apple has the best customer service. In and ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  word_count\n",
       "0  I have to say, Apple has by far the best custo...          19\n",
       "1  iOS 7 is so fricking smooth & beautiful!! #Tha...          10\n",
       "2                                      LOVE U @APPLE           3\n",
       "3  Thank you @apple, loving my new iPhone 5S!!!!!...          12\n",
       "4  .@apple has the best customer service. In and ...          16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apple_tweets['word_count'] = Apple_tweets['Tweet'].apply(lambda x: len(str(x).split(\" \")))\n",
    "Apple_tweets[['Tweet','word_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Characters- including spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:34.155826Z",
     "start_time": "2020-04-16T13:31:34.040168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I have to say, Apple has by far the best custo...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>iOS 7 is so fricking smooth &amp; beautiful!! #Tha...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LOVE U @APPLE</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Thank you @apple, loving my new iPhone 5S!!!!!...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>.@apple has the best customer service. In and ...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  char_count\n",
       "0  I have to say, Apple has by far the best custo...         101\n",
       "1  iOS 7 is so fricking smooth & beautiful!! #Tha...          60\n",
       "2                                      LOVE U @APPLE          13\n",
       "3  Thank you @apple, loving my new iPhone 5S!!!!!...          91\n",
       "4  .@apple has the best customer service. In and ...          82"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apple_tweets['char_count'] = Apple_tweets['Tweet'].str.len() ## this also includes spaces\n",
    "Apple_tweets[['Tweet','char_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:34.266564Z",
     "start_time": "2020-04-16T13:31:34.156823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I have to say, Apple has by far the best custo...</td>\n",
       "      <td>4.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>iOS 7 is so fricking smooth &amp; beautiful!! #Tha...</td>\n",
       "      <td>5.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LOVE U @APPLE</td>\n",
       "      <td>3.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Thank you @apple, loving my new iPhone 5S!!!!!...</td>\n",
       "      <td>7.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>.@apple has the best customer service. In and ...</td>\n",
       "      <td>4.187500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  avg_word\n",
       "0  I have to say, Apple has by far the best custo...  4.368421\n",
       "1  iOS 7 is so fricking smooth & beautiful!! #Tha...  5.100000\n",
       "2                                      LOVE U @APPLE  3.666667\n",
       "3  Thank you @apple, loving my new iPhone 5S!!!!!...  7.272727\n",
       "4  .@apple has the best customer service. In and ...  4.187500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_word(sentence):\n",
    "    words = sentence.split()\n",
    "    return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "Apple_tweets['avg_word'] = Apple_tweets['Tweet'].apply(lambda x: avg_word(x))\n",
    "Apple_tweets[['Tweet','avg_word']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:34.498950Z",
     "start_time": "2020-04-16T13:31:34.269522Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:34.662507Z",
     "start_time": "2020-04-16T13:31:34.499905Z"
    }
   },
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:34.847976Z",
     "start_time": "2020-04-16T13:31:34.663501Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I have to say, Apple has by far the best custo...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>iOS 7 is so fricking smooth &amp; beautiful!! #Tha...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LOVE U @APPLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Thank you @apple, loving my new iPhone 5S!!!!!...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>.@apple has the best customer service. In and ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  stopwords\n",
       "0  I have to say, Apple has by far the best custo...          6\n",
       "1  iOS 7 is so fricking smooth & beautiful!! #Tha...          2\n",
       "2                                      LOVE U @APPLE          0\n",
       "3  Thank you @apple, loving my new iPhone 5S!!!!!...          2\n",
       "4  .@apple has the best customer service. In and ...          8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "Apple_tweets['stopwords'] = Apple_tweets['Tweet'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "Apple_tweets[['Tweet','stopwords']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of special character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:34.919782Z",
     "start_time": "2020-04-16T13:31:34.848973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>hastags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I have to say, Apple has by far the best custo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>iOS 7 is so fricking smooth &amp; beautiful!! #Tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LOVE U @APPLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Thank you @apple, loving my new iPhone 5S!!!!!...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>.@apple has the best customer service. In and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  hastags\n",
       "0  I have to say, Apple has by far the best custo...        0\n",
       "1  iOS 7 is so fricking smooth & beautiful!! #Tha...        1\n",
       "2                                      LOVE U @APPLE        0\n",
       "3  Thank you @apple, loving my new iPhone 5S!!!!!...        2\n",
       "4  .@apple has the best customer service. In and ...        0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apple_tweets['hastags'] = Apple_tweets['Tweet'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "Apple_tweets[['Tweet','hastags']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:35.060445Z",
     "start_time": "2020-04-16T13:31:34.921777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I have to say, Apple has by far the best custo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>iOS 7 is so fricking smooth &amp; beautiful!! #Tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LOVE U @APPLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Thank you @apple, loving my new iPhone 5S!!!!!...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>.@apple has the best customer service. In and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  numerics\n",
       "0  I have to say, Apple has by far the best custo...         0\n",
       "1  iOS 7 is so fricking smooth & beautiful!! #Tha...         1\n",
       "2                                      LOVE U @APPLE         0\n",
       "3  Thank you @apple, loving my new iPhone 5S!!!!!...         0\n",
       "4  .@apple has the best customer service. In and ...         0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apple_tweets['numerics'] = Apple_tweets['Tweet'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "Apple_tweets[['Tweet','numerics']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Uppercase Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:35.177127Z",
     "start_time": "2020-04-16T13:31:35.061403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I have to say, Apple has by far the best custo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>iOS 7 is so fricking smooth &amp; beautiful!! #Tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LOVE U @APPLE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Thank you @apple, loving my new iPhone 5S!!!!!...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>.@apple has the best customer service. In and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  upper\n",
       "0  I have to say, Apple has by far the best custo...      2\n",
       "1  iOS 7 is so fricking smooth & beautiful!! #Tha...      0\n",
       "2                                      LOVE U @APPLE      3\n",
       "3  Thank you @apple, loving my new iPhone 5S!!!!!...      1\n",
       "4  .@apple has the best customer service. In and ...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apple_tweets['upper'] = Apple_tweets['Tweet'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "Apple_tweets[['Tweet','upper']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower Case conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:35.271841Z",
     "start_time": "2020-04-16T13:31:35.178091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i have to say, apple has by far the best custo...\n",
       "1    ios 7 is so fricking smooth & beautiful!! #tha...\n",
       "2                                        love u @apple\n",
       "3    thank you @apple, loving my new iphone 5s!!!!!...\n",
       "4    .@apple has the best customer service. in and ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apple_tweets['Tweet'] = Apple_tweets['Tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "Apple_tweets['Tweet'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removal of Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:35.468354Z",
     "start_time": "2020-04-16T13:31:35.272838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i have to say apple has by far the best custom...\n",
       "1    ios 7 is so fricking smooth  beautiful thanxap...\n",
       "2                                         love u apple\n",
       "3    thank you apple loving my new iphone 5s apple ...\n",
       "4    apple has the best customer service in and out...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apple_tweets['Tweet'] = Apple_tweets['Tweet'].str.replace('[^\\w\\s]','')\n",
    "Apple_tweets['Tweet'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removal of StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:35.634907Z",
     "start_time": "2020-04-16T13:31:35.469312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    say apple far best customer care service ever ...\n",
       "1     ios 7 fricking smooth beautiful thanxapple apple\n",
       "2                                         love u apple\n",
       "3    thank apple loving new iphone 5s apple iphone5...\n",
       "4          apple best customer service new phone 10min\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "Apple_tweets['Tweet'] = Apple_tweets['Tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "Apple_tweets['Tweet'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Words Removal\n",
    "1. **We will create a list of 10 frequently occuring words and then decide if we need to remove it or retain it.**\n",
    "2. **Reason is that this file has tweets related to Apple.. So no point in keeping the word like Apple, unless we have tweets from other brands**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:35.748567Z",
     "start_time": "2020-04-16T13:31:35.636864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apple              1297\n",
       "iphone              257\n",
       "new                 113\n",
       "5s                   91\n",
       "ipad                 88\n",
       "itunes               79\n",
       "phone                75\n",
       "ipod                 71\n",
       "ipodplayerpromo      60\n",
       "get                  60\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(Apple_tweets['Tweet']).split()).value_counts()[:10]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:35.871105Z",
     "start_time": "2020-04-16T13:31:35.749563Z"
    }
   },
   "outputs": [],
   "source": [
    "freq =['apple','get']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **As we are talking about multiple products hence iphone will be kept, similarly some tweets do relate to old products without mentioning the word old, hence even new would be kept in the tweets.**\n",
    "2. **hence only apple and get would be removed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:36.009696Z",
     "start_time": "2020-04-16T13:31:35.872064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    say far best customer care service ever receiv...\n",
       "1           ios 7 fricking smooth beautiful thanxapple\n",
       "2                                               love u\n",
       "3    thank loving new iphone 5s iphone5s pictwitter...\n",
       "4                best customer service new phone 10min\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apple_tweets['Tweet'] = Apple_tweets['Tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "Apple_tweets['Tweet'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rare Words Removal\n",
    "**This is done as association of these less occurring words with the existing words could be a noise**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:36.118405Z",
     "start_time": "2020-04-16T13:31:36.011690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "doctorveritas     1\n",
       "caterpillarinc    1\n",
       "vai               1\n",
       "fysiek            1\n",
       "ehhh              1\n",
       "jki               1\n",
       "jedipad           1\n",
       "dominate          1\n",
       "180               1\n",
       "geen              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(Apple_tweets['Tweet']).split()).value_counts()[-10:]\n",
    "freq\n",
    "## As it is difficult to make out if these words will have association in text analytics or not, \n",
    "## hence to start with these words are kept in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming -refers to the removal of suffices, like “ing”, “ly”, “s”, etc. by a simple rule-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:36.253048Z",
     "start_time": "2020-04-16T13:31:36.121398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    say far best custom care servic ever receiv ap...\n",
       "1                   io 7 frick smooth beauti thanxappl\n",
       "2                                               love u\n",
       "3    thank love new iphon 5s iphone5 pictwittercomx...\n",
       "4                   best custom servic new phone 10min\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "Apple_tweets['Tweet'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:36.377750Z",
     "start_time": "2020-04-16T13:31:36.256038Z"
    }
   },
   "outputs": [],
   "source": [
    "def Tweet(x):\n",
    "    if x >= 0:\n",
    "        return \"Positive\"\n",
    "    \n",
    "    else: return \"Negative\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T10:52:41.105760Z",
     "start_time": "2020-04-10T10:52:41.100002Z"
    }
   },
   "source": [
    "### Now to get the sentiments as positive and negative , convert the Avg column . If value is >= 0  then tweet is Positive, else tweet is Negative. This will make a dependent variable as a binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:36.482465Z",
     "start_time": "2020-04-16T13:31:36.381701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Avg</th>\n",
       "      <th>totalwords</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hastags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>say far best customer care service ever receiv...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>101</td>\n",
       "      <td>4.368421</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ios 7 fricking smooth beautiful thanxapple</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>love u</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>thank loving new iphone 5s iphone5s pictwitter...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>91</td>\n",
       "      <td>7.272727</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>best customer service new phone 10min</td>\n",
       "      <td>1.8</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>82</td>\n",
       "      <td>4.187500</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Avg  totalwords  \\\n",
       "0  say far best customer care service ever receiv...  2.0          19   \n",
       "1         ios 7 fricking smooth beautiful thanxapple  2.0          10   \n",
       "2                                             love u  1.8           3   \n",
       "3  thank loving new iphone 5s iphone5s pictwitter...  1.8          11   \n",
       "4              best customer service new phone 10min  1.8          16   \n",
       "\n",
       "   word_count  char_count  avg_word  stopwords  hastags  numerics  upper  \\\n",
       "0          19         101  4.368421          6        0         0      2   \n",
       "1          10          60  5.100000          2        1         1      0   \n",
       "2           3          13  3.666667          0        0         0      3   \n",
       "3          12          91  7.272727          2        2         0      1   \n",
       "4          16          82  4.187500          8        0         0      0   \n",
       "\n",
       "  Sentiment  \n",
       "0  Positive  \n",
       "1  Positive  \n",
       "2  Positive  \n",
       "3  Positive  \n",
       "4  Positive  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apple_tweets[\"Sentiment\"] = Apple_tweets[\"Avg\"].apply(Tweet)\n",
    "\n",
    "Apple_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:36.577178Z",
     "start_time": "2020-04-16T13:31:36.484426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1181 entries, 0 to 1180\n",
      "Data columns (total 11 columns):\n",
      "Tweet         1181 non-null object\n",
      "Avg           1181 non-null float64\n",
      "totalwords    1181 non-null int64\n",
      "word_count    1181 non-null int64\n",
      "char_count    1181 non-null int64\n",
      "avg_word      1181 non-null float64\n",
      "stopwords     1181 non-null int64\n",
      "hastags       1181 non-null int64\n",
      "numerics      1181 non-null int64\n",
      "upper         1181 non-null int64\n",
      "Sentiment     1181 non-null object\n",
      "dtypes: float64(2), int64(7), object(2)\n",
      "memory usage: 101.6+ KB\n"
     ]
    }
   ],
   "source": [
    "Apple_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at distribution of different sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:36.798625Z",
     "start_time": "2020-04-16T13:31:36.578174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "Apple_tweets.Sentiment.value_counts().plot(kind='pie', autopct='%1.0f%%', colors=[\"red\",\"green\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:36.831530Z",
     "start_time": "2020-04-16T13:31:36.799584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1181 entries, 0 to 1180\n",
      "Data columns (total 11 columns):\n",
      "Tweet         1181 non-null object\n",
      "Avg           1181 non-null float64\n",
      "totalwords    1181 non-null int64\n",
      "word_count    1181 non-null int64\n",
      "char_count    1181 non-null int64\n",
      "avg_word      1181 non-null float64\n",
      "stopwords     1181 non-null int64\n",
      "hastags       1181 non-null int64\n",
      "numerics      1181 non-null int64\n",
      "upper         1181 non-null int64\n",
      "Sentiment     1181 non-null object\n",
      "dtypes: float64(2), int64(7), object(2)\n",
      "memory usage: 101.6+ KB\n"
     ]
    }
   ],
   "source": [
    "Apple_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:36.925285Z",
     "start_time": "2020-04-16T13:31:36.832496Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_features = Apple_tweets.iloc[:, 0].values\n",
    "labels = Apple_tweets.iloc[:, 10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:37.078835Z",
     "start_time": "2020-04-16T13:31:36.926245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['say far best customer care service ever received appstore',\n",
       "       'ios 7 fricking smooth beautiful thanxapple', 'love u', ...,\n",
       "       'freaking cows freak', 'hate phone working im going freak',\n",
       "       'agounalakis thats nasty nasty brat'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:37.174614Z",
     "start_time": "2020-04-16T13:31:37.079832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Positive', 'Positive', ..., 'Negative', 'Negative',\n",
       "       'Negative'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:37.365103Z",
     "start_time": "2020-04-16T13:31:37.175579Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer (max_features=2500, min_df=7, max_df=0.8)\n",
    "processed_features = vectorizer.fit_transform(processed_features).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:37.445855Z",
     "start_time": "2020-04-16T13:31:37.366069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.8, max_features=2500, min_df=7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:37.573551Z",
     "start_time": "2020-04-16T13:31:37.446854Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_features, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:37.685213Z",
     "start_time": "2020-04-16T13:31:37.574509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Negative', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Negative', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Negative', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Negative', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Negative', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Negative', 'Negative',\n",
       "       'Negative', 'Negative', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Positive', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Positive', 'Negative', 'Negative', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Negative',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Negative', 'Negative', 'Negative', 'Negative', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Negative', 'Positive',\n",
       "       'Negative', 'Positive', 'Negative', 'Positive', 'Negative',\n",
       "       'Positive', 'Positive', 'Positive', 'Negative', 'Positive',\n",
       "       'Positive', 'Negative', 'Positive', 'Positive', 'Negative',\n",
       "       'Negative', 'Negative', 'Positive', 'Negative'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:38.652626Z",
     "start_time": "2020-04-16T13:31:37.686211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF_model = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "RF_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Matrix on train data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:38.820178Z",
     "start_time": "2020-04-16T13:31:38.653625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9449152542372882\n",
      "[[380  45]\n",
      " [  7 512]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.98      0.89      0.94       425\n",
      "    Positive       0.92      0.99      0.95       519\n",
      "\n",
      "    accuracy                           0.94       944\n",
      "   macro avg       0.95      0.94      0.94       944\n",
      "weighted avg       0.95      0.94      0.94       944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_train_predict = RF_model.predict(X_train)\n",
    "model_score =RF_model.score(X_train, y_train)\n",
    "print(model_score)\n",
    "print(metrics.confusion_matrix(y_train, y_train_predict))\n",
    "print(metrics.classification_report(y_train, y_train_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Matrix on test data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:38.893022Z",
     "start_time": "2020-04-16T13:31:38.822175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7130801687763713\n",
      "[[75 41]\n",
      " [27 94]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.65      0.69       116\n",
      "    Positive       0.70      0.78      0.73       121\n",
      "\n",
      "    accuracy                           0.71       237\n",
      "   macro avg       0.72      0.71      0.71       237\n",
      "weighted avg       0.72      0.71      0.71       237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_predict = RF_model.predict(X_test)\n",
    "model_score = RF_model.score(X_test, y_test)\n",
    "print(model_score)\n",
    "print(metrics.confusion_matrix(y_test, y_test_predict))\n",
    "print(metrics.classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:39.046609Z",
     "start_time": "2020-04-16T13:31:38.893982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "DT_model= tree.DecisionTreeClassifier(random_state=1)\n",
    "DT_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Matrix on train data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:39.124366Z",
     "start_time": "2020-04-16T13:31:39.047572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9449152542372882\n",
      "[[386  39]\n",
      " [ 13 506]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.97      0.91      0.94       425\n",
      "    Positive       0.93      0.97      0.95       519\n",
      "\n",
      "    accuracy                           0.94       944\n",
      "   macro avg       0.95      0.94      0.94       944\n",
      "weighted avg       0.95      0.94      0.94       944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = DT_model.predict(X_train)\n",
    "model_score = DT_model.score(X_train, y_train)\n",
    "print(model_score)\n",
    "print(metrics.confusion_matrix(y_train, y_train_predict))\n",
    "print(metrics.classification_report(y_train, y_train_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Matrix on test data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:39.251060Z",
     "start_time": "2020-04-16T13:31:39.125363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6751054852320675\n",
      "[[76 40]\n",
      " [37 84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.67      0.66      0.66       116\n",
      "    Positive       0.68      0.69      0.69       121\n",
      "\n",
      "    accuracy                           0.68       237\n",
      "   macro avg       0.67      0.67      0.67       237\n",
      "weighted avg       0.68      0.68      0.67       237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_predict = DT_model.predict(X_test)\n",
    "model_score = DT_model.score(X_test, y_test)\n",
    "print(model_score)\n",
    "print(metrics.confusion_matrix(y_test, y_test_predict))\n",
    "print(metrics.classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinominal Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn=MultinomialNB()\n",
    "mn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Matrix on train data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7796610169491526\n",
      "[[265 160]\n",
      " [ 48 471]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.85      0.62      0.72       425\n",
      "    Positive       0.75      0.91      0.82       519\n",
      "\n",
      "    accuracy                           0.78       944\n",
      "   macro avg       0.80      0.77      0.77       944\n",
      "weighted avg       0.79      0.78      0.77       944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = mn.predict(X_train)\n",
    "model_score = mn.score(X_train, y_train)\n",
    "print(model_score)\n",
    "print(metrics.confusion_matrix(y_train, y_train_predict))\n",
    "print(metrics.classification_report(y_train, y_train_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Matrix on test data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7046413502109705\n",
      "[[73 43]\n",
      " [27 94]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.63      0.68       116\n",
      "    Positive       0.69      0.78      0.73       121\n",
      "\n",
      "    accuracy                           0.70       237\n",
      "   macro avg       0.71      0.70      0.70       237\n",
      "weighted avg       0.71      0.70      0.70       237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_predict = mn.predict(X_test)\n",
    "model_score = mn.score(X_test, y_test)\n",
    "print(model_score)\n",
    "print(metrics.confusion_matrix(y_test, y_test_predict))\n",
    "print(metrics.classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:39.530278Z",
     "start_time": "2020-04-16T13:31:39.252023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "LDA_model= LinearDiscriminantAnalysis()\n",
    "LDA_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Matrix on train data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:39.568177Z",
     "start_time": "2020-04-16T13:31:39.532273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.809322033898305\n",
      "[[303 122]\n",
      " [ 58 461]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.84      0.71      0.77       425\n",
      "    Positive       0.79      0.89      0.84       519\n",
      "\n",
      "    accuracy                           0.81       944\n",
      "   macro avg       0.82      0.80      0.80       944\n",
      "weighted avg       0.81      0.81      0.81       944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = LDA_model.predict(X_train)\n",
    "model_score = LDA_model.score(X_train, y_train)\n",
    "print(model_score)\n",
    "print(metrics.confusion_matrix(y_train, y_train_predict))\n",
    "print(metrics.classification_report(y_train, y_train_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance Matrix on test data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:39.650955Z",
     "start_time": "2020-04-16T13:31:39.570173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70042194092827\n",
      "[[76 40]\n",
      " [31 90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.71      0.66      0.68       116\n",
      "    Positive       0.69      0.74      0.72       121\n",
      "\n",
      "    accuracy                           0.70       237\n",
      "   macro avg       0.70      0.70      0.70       237\n",
      "weighted avg       0.70      0.70      0.70       237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_predict = LDA_model.predict(X_test)\n",
    "model_score = LDA_model.score(X_test, y_test)\n",
    "print(model_score)\n",
    "print(metrics.confusion_matrix(y_test, y_test_predict))\n",
    "print(metrics.classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:39.792577Z",
     "start_time": "2020-04-16T13:31:39.651953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNN_model=KNeighborsClassifier()\n",
    "KNN_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Matrix on train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:40.546597Z",
     "start_time": "2020-04-16T13:31:39.793574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7182203389830508\n",
      "[[215 210]\n",
      " [ 56 463]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.79      0.51      0.62       425\n",
      "    Positive       0.69      0.89      0.78       519\n",
      "\n",
      "    accuracy                           0.72       944\n",
      "   macro avg       0.74      0.70      0.70       944\n",
      "weighted avg       0.74      0.72      0.71       944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = KNN_model.predict(X_train)\n",
    "model_score = KNN_model.score(X_train, y_train)\n",
    "print(model_score)\n",
    "print(metrics.confusion_matrix(y_train, y_train_predict))\n",
    "print(metrics.classification_report(y_train, y_train_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance Matrix on test data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-16T13:31:40.730109Z",
     "start_time": "2020-04-16T13:31:40.547561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6075949367088608\n",
      "[[49 67]\n",
      " [26 95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.65      0.42      0.51       116\n",
      "    Positive       0.59      0.79      0.67       121\n",
      "\n",
      "    accuracy                           0.61       237\n",
      "   macro avg       0.62      0.60      0.59       237\n",
      "weighted avg       0.62      0.61      0.59       237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_predict = KNN_model.predict(X_test)\n",
    "model_score = KNN_model.score(X_test, y_test)\n",
    "print(model_score)\n",
    "print(metrics.confusion_matrix(y_test, y_test_predict))\n",
    "print(metrics.classification_report(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application creation to see positive and negative comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_comment_apple(msg): #create a function that detects positve or negative taking user input\n",
    "    import re\n",
    "    import string\n",
    "    text=msg\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('[''\"\"...]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('[^a-z, ,]','',text)\n",
    "    ddd=pd.DataFrame(index=range(0,1))\n",
    "    ddd['Message']=text\n",
    "    mess_bow=vectorizer.transform(ddd.Message)\n",
    "    message_co= mess_bow.toarray()\n",
    "    input_variables= message_co\n",
    "    final_features = input_variables\n",
    "    prediction = LDA_model.predict(final_features)\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentimentation comments created now its time to set them from user input(save the dataset created in csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Avg</th>\n",
       "      <th>totalwords</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hastags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>say far best customer care service ever receiv...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>101</td>\n",
       "      <td>4.368421</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ios 7 fricking smooth beautiful thanxapple</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>love u</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>thank loving new iphone 5s iphone5s pictwitter...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>91</td>\n",
       "      <td>7.272727</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Avg  totalwords  \\\n",
       "0  say far best customer care service ever receiv...  2.0          19   \n",
       "1         ios 7 fricking smooth beautiful thanxapple  2.0          10   \n",
       "2                                             love u  1.8           3   \n",
       "3  thank loving new iphone 5s iphone5s pictwitter...  1.8          11   \n",
       "\n",
       "   word_count  char_count  avg_word  stopwords  hastags  numerics  upper  \\\n",
       "0          19         101  4.368421          6        0         0      2   \n",
       "1          10          60  5.100000          2        1         1      0   \n",
       "2           3          13  3.666667          0        0         0      3   \n",
       "3          12          91  7.272727          2        2         0      1   \n",
       "\n",
       "  Sentiment  \n",
       "0  Positive  \n",
       "1  Positive  \n",
       "2  Positive  \n",
       "3  Positive  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apple_tweets.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create your directory to save and view the dataset sentiment whether its positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apple_tweets.to_csv('C:\\\\Users\\\\Home\\\\Desktop\\\\appletweetcommentfeedback.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the Text Message best customer service new phone 10min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg=input('Enter the Text Message ')\n",
    "tweet_comment_apple(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An application has been build that actually uses your model's intelligence and it works to detect automatically where the tweet comments if its positive or negative using a wide parametric and non parametric machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 5 models given above, considering the different between train and test dataset performance parameters, LDA has performed the best. As per the norm difference between the test and train matrix performance parameters can be within +/- 10% for the model to be valid. For a Negative class, for LDA, difference is within the norms. However for Positive class it is bit higher.\n",
    "\n",
    "\n",
    "We can also look at KNN model outout as well wherein difference between train and test is within +/- 10% but the recall value for Negative sentiments is quite low.\n",
    "\n",
    "In terms of sentiments, based on the organization objective, both positive and  negative metrics could be analyzed to define the marketing strategy e.g. based on positive sentiments organization can decide on what needs to be done for a specific product to increase the positive sentiment. Similarly based on the negative keywords organization can decide what needs to be corrected to decrease the negative sentiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
